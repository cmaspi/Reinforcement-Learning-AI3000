{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('cyberpunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Discrete(2)\n",
      "state space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "ENV_NAME = 'CartPole-v0'\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "print(f'action space: {env.action_space}')\n",
    "print(f'state space: {env.observation_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "15\n",
      "12\n",
      "17\n",
      "8\n",
      "10\n",
      "19\n",
      "14\n",
      "69\n",
      "39\n",
      "[29.0, 15.0, 12.0, 17.0, 8.0, 10.0, 19.0, 14.0, 69.0, 39.0]\n"
     ]
    }
   ],
   "source": [
    "def random_agent(env):\n",
    "    return np.random.choice(env.action_space.n, 1)[0]\n",
    "\n",
    "\n",
    "def simulate(num_episodes: int, render=False):\n",
    "    env = gym.make(ENV_NAME)\n",
    "    scores = []\n",
    "    for episode in range(1, num_episodes+1):\n",
    "        total_score = 0\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        itr = 0\n",
    "        while not done:\n",
    "            itr += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = random_agent(env)\n",
    "            next_state, reward, done, *_ = env.step(action)\n",
    "            total_score += reward\n",
    "        scores.append(total_score)\n",
    "        print(itr)\n",
    "    env.close()\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = simulate(10)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random agent performs poorly, the game stops within a very short time frame because it breaches one of the two mentioned conditions, that are\n",
    "\n",
    "1. It shouldn't be off by more than 2.4 units\n",
    "2. The angle from vertical shouldn't be more than 15 degrees.\n",
    "\n",
    "A reward of +1 is given for each time stamp that the pole stays upright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.37297821044922\n",
      "9.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [00:08<01:09, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030400006100535393\n",
      "9.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 204/1000 [00:14<00:43, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010975359939038754\n",
      "9.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 302/1000 [00:20<00:42, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004976675845682621\n",
      "9.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 404/1000 [00:25<00:33, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027270670980215073\n",
      "9.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 504/1000 [00:31<00:27, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019136574119329453\n",
      "9.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 604/1000 [00:37<00:21, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013098529307171702\n",
      "9.34375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 704/1000 [00:42<00:16, 17.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009417744586244226\n",
      "9.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 804/1000 [00:48<00:10, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007044861558824778\n",
      "9.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 904/1000 [00:53<00:05, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005258867749944329\n",
      "9.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:59<00:00, 16.93it/s]\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Sequential()\n",
    "        self.layer1.append(nn.Linear(4, 48))\n",
    "        self.layer1.append(nn.ReLU())\n",
    "        # self.layer2 = nn.Sequential()\n",
    "        # self.layer2.append(nn.Linear(48, 36))\n",
    "        # self.layer2.append(nn.ReLU())\n",
    "        self.layer3 = nn.Sequential()\n",
    "        self.layer3.append(nn.Linear(48, 2))\n",
    "        self.layer3.append(nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.layer1(X)\n",
    "        # X = self.layer2(X)\n",
    "        return self.layer3(X)\n",
    "\n",
    "\n",
    "class GAME:\n",
    "    def __init__(self) -> None:\n",
    "        self.model = MLP()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "\n",
    "    def loss_func(self, trajectories):\n",
    "        m = len(trajectories)\n",
    "        loss = 0\n",
    "        for i in trajectories:\n",
    "            rewards = torch.tensor([x.reward for x in i][::-1])\n",
    "            rewards = torch.cumsum(rewards, dim=0)\n",
    "            inv_idx = torch.arange(rewards.size(0)-1, -1, -1).long()\n",
    "            rewards = rewards[inv_idx]\n",
    "            probs = torch.stack([x.prob for x in i])\n",
    "            temp = probs@rewards\n",
    "            loss += temp\n",
    "        return -loss/m\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        trajectories = [[] for _ in range(batch_size)]\n",
    "        TRANSITION = namedtuple('transition', ('state', 'prob', 'reward'))\n",
    "        mean_reward = 0\n",
    "        for epoch in range(batch_size):\n",
    "            state = torch.tensor(self.env.reset())\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                temp = self.model.forward(state)\n",
    "                action = torch.argmax(temp).detach().__int__()\n",
    "                prob = temp[action]\n",
    "                next_state, reward, done, *_ = self.env.step(action)\n",
    "                temp = TRANSITION(state, prob, reward)\n",
    "                trajectories[epoch].append(temp)\n",
    "                state = torch.tensor(next_state)\n",
    "                mean_reward += reward\n",
    "        return trajectories, mean_reward/batch_size\n",
    "    \n",
    "    def train(self, num_episodes):\n",
    "        for itr in tqdm(range(num_episodes)):\n",
    "            trajectories, mean_reward = self.sample(32)\n",
    "            loss = self.loss_func(trajectories)\n",
    "            self.optimizer.zero_grad()\n",
    "            if itr%100==0:\n",
    "                print(loss.item())\n",
    "                print(mean_reward)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    \n",
    "    def test(self, num_episodes, render=False):\n",
    "        for itr in range(num_episodes):\n",
    "            state = torch.tensor(self.env.reset())\n",
    "            done = False\n",
    "            cumulative_reward = 0\n",
    "            while not done:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                action = torch.argmax(self.model.forward(state)).detach().__int__()\n",
    "                next_state, reward, done, *_ = self.env.step(action)\n",
    "                state = torch.tensor(next_state)\n",
    "                cumulative_reward += reward\n",
    "            print(cumulative_reward)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "game = GAME()   \n",
    "game.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "9.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "game.test(10)\n",
    "game.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8469e-07, -4.5016e-06, -1.4246e-07,  6.6909e-06],\n",
      "        [ 2.3424e-06, -4.3390e-06, -1.5319e-06,  6.2863e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.6967e-07, -1.2367e-06, -4.3809e-07,  1.7916e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7238e-06, -3.2123e-06, -1.1267e-06,  4.6544e-06],\n",
      "        [ 2.3453e-06, -4.3546e-06, -1.5334e-06,  6.3091e-06],\n",
      "        [ 1.8258e-06, -3.3769e-06, -1.1943e-06,  4.8923e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9894e-06, -3.6978e-06, -1.3006e-06,  5.3577e-06],\n",
      "        [-6.0389e-11, -1.7685e-08,  1.8422e-10,  2.6311e-08],\n",
      "        [ 2.7422e-06, -5.0894e-06, -1.7931e-06,  7.3737e-06],\n",
      "        [ 1.7663e-06, -3.2704e-06, -1.1552e-06,  4.7380e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9711e-06, -3.6513e-06, -1.2891e-06,  5.2899e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.9881e-09, -6.5673e-07, -4.1023e-09,  9.7600e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9484e-07, -4.7593e-06, -1.4995e-07,  7.0739e-06],\n",
      "        [ 1.1463e-06, -2.1202e-06, -7.4982e-07,  3.0717e-06],\n",
      "        [ 1.0333e-06, -1.9121e-06, -6.7583e-07,  2.7701e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.2182e-06, -4.1243e-06, -1.4502e-06,  5.9756e-06],\n",
      "        [ 1.3428e-06, -2.4879e-06, -8.7819e-07,  3.6044e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.7842e-06, -5.1621e-06, -1.8207e-06,  7.4788e-06],\n",
      "        [ 1.5494e-06, -2.8655e-06, -1.0135e-06,  4.1513e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9925e-06, -3.6940e-06, -1.3030e-06,  5.3519e-06],\n",
      "        [ 2.4390e-06, -4.5361e-06, -1.5945e-06,  6.5723e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.6158e-06, -8.5613e-06, -3.0183e-06,  1.2404e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.3297e-06, -4.3170e-06, -1.5236e-06,  6.2544e-06],\n",
      "        [ 3.2024e-06, -5.9474e-06, -2.0938e-06,  8.6169e-06],\n",
      "        [ 1.2925e-06, -2.3943e-06, -8.4537e-07,  3.4684e-06],\n",
      "        [ 1.6355e-06, -3.0368e-06, -1.0693e-06,  4.3998e-06],\n",
      "        [ 6.1024e-07, -1.1345e-06, -3.9895e-07,  1.6437e-06],\n",
      "        [ 1.7480e-06, -3.2486e-06, -1.1428e-06,  4.7068e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 9.5224e-06, -1.7678e-05, -6.2263e-06,  2.5613e-05],\n",
      "        [-2.2924e-08, -1.7328e-06,  1.1208e-07,  2.6903e-06],\n",
      "        [ 7.8175e-07, -1.4435e-06, -5.1142e-07,  2.0912e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.9057e-06, -3.5496e-06, -1.2456e-06,  5.1432e-06]])\n",
      "tensor([-2.2024e-05, -2.8503e-04,  0.0000e+00,  0.0000e+00, -8.1484e-05,\n",
      "         0.0000e+00, -2.0977e-04, -2.8539e-04, -2.2217e-04,  0.0000e+00,\n",
      "        -2.4208e-04, -3.0088e-08, -3.3369e-04, -2.1493e-04,  0.0000e+00,\n",
      "         0.0000e+00, -2.3985e-04,  0.0000e+00, -1.6808e-06,  0.0000e+00,\n",
      "        -2.3248e-05, -1.3949e-04, -1.2573e-04,  0.0000e+00, -2.6993e-04,\n",
      "        -1.6340e-04,  0.0000e+00, -3.3880e-04, -1.8853e-04,  0.0000e+00,\n",
      "        -2.4246e-04, -2.9680e-04,  0.0000e+00, -5.6167e-04,  0.0000e+00,\n",
      "        -2.8349e-04, -3.8969e-04, -1.5727e-04, -1.9901e-04, -7.4259e-05,\n",
      "        -2.1271e-04,  0.0000e+00,  0.0000e+00, -1.1587e-03, -6.7519e-06,\n",
      "        -9.5122e-05,  0.0000e+00, -2.3190e-04])\n",
      "tensor([[ 7.8703e-06,  3.3359e-04,  0.0000e+00,  0.0000e+00,  7.0698e-05,\n",
      "          0.0000e+00,  3.7245e-04,  3.7131e-04,  4.0213e-04,  0.0000e+00,\n",
      "          3.1021e-04,  7.5062e-09,  1.9426e-04,  2.0626e-04,  0.0000e+00,\n",
      "          0.0000e+00,  3.0485e-04,  0.0000e+00,  5.4931e-07,  0.0000e+00,\n",
      "          5.4673e-06,  2.0651e-04,  1.7841e-04,  0.0000e+00,  1.3500e-04,\n",
      "          2.1169e-04,  0.0000e+00,  3.0507e-04,  2.3809e-04,  0.0000e+00,\n",
      "          1.9952e-04,  3.5352e-04,  0.0000e+00,  3.0463e-04,  0.0000e+00,\n",
      "          2.3190e-04,  1.9936e-04,  2.2609e-04,  2.3711e-04,  1.5421e-04,\n",
      "          3.9412e-04,  0.0000e+00,  0.0000e+00,  5.0522e-04,  1.1393e-06,\n",
      "          1.4568e-04,  0.0000e+00,  3.4300e-04],\n",
      "        [-7.7580e-06, -3.3350e-04,  0.0000e+00,  0.0000e+00, -7.0612e-05,\n",
      "          0.0000e+00, -3.7227e-04, -3.7125e-04, -4.0203e-04,  0.0000e+00,\n",
      "         -3.1010e-04, -1.5035e-09, -1.9414e-04, -2.0609e-04,  0.0000e+00,\n",
      "          0.0000e+00, -3.0484e-04,  0.0000e+00, -4.7974e-07,  0.0000e+00,\n",
      "         -5.3765e-06, -2.0655e-04, -1.7838e-04,  0.0000e+00, -1.3490e-04,\n",
      "         -2.1166e-04,  0.0000e+00, -3.0502e-04, -2.3798e-04,  0.0000e+00,\n",
      "         -1.9938e-04, -3.5346e-04,  0.0000e+00, -3.0456e-04,  0.0000e+00,\n",
      "         -2.3181e-04, -1.9925e-04, -2.2617e-04, -2.3696e-04, -1.5415e-04,\n",
      "         -3.9398e-04,  0.0000e+00,  0.0000e+00, -5.0509e-04, -1.0408e-06,\n",
      "         -1.4562e-04,  0.0000e+00, -3.4290e-04]])\n",
      "tensor([ 0.0005, -0.0005])\n"
     ]
    }
   ],
   "source": [
    "for p in game.model.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
